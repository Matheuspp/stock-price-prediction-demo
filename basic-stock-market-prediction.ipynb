{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:25.359151Z",
     "iopub.status.busy": "2021-11-11T05:12:25.358677Z",
     "iopub.status.idle": "2021-11-11T05:12:30.756869Z",
     "shell.execute_reply": "2021-11-11T05:12:30.755771Z",
     "shell.execute_reply.started": "2021-11-11T05:12:25.359022Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#setting figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "#for normalizing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:30.7589Z",
     "iopub.status.busy": "2021-11-11T05:12:30.758612Z",
     "iopub.status.idle": "2021-11-11T05:12:30.82333Z",
     "shell.execute_reply": "2021-11-11T05:12:30.822523Z",
     "shell.execute_reply.started": "2021-11-11T05:12:30.758862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993-01-29</td>\n",
       "      <td>43.968750</td>\n",
       "      <td>43.968750</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>43.937500</td>\n",
       "      <td>26.299288</td>\n",
       "      <td>1003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>43.968750</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>43.968750</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>26.486324</td>\n",
       "      <td>480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993-02-02</td>\n",
       "      <td>44.218750</td>\n",
       "      <td>44.375000</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>44.343750</td>\n",
       "      <td>26.542448</td>\n",
       "      <td>201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>44.406250</td>\n",
       "      <td>44.843750</td>\n",
       "      <td>44.375000</td>\n",
       "      <td>44.812500</td>\n",
       "      <td>26.822998</td>\n",
       "      <td>529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-02-04</td>\n",
       "      <td>44.968750</td>\n",
       "      <td>45.093750</td>\n",
       "      <td>44.468750</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>26.935240</td>\n",
       "      <td>531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>249.520004</td>\n",
       "      <td>262.799988</td>\n",
       "      <td>249.050003</td>\n",
       "      <td>261.200012</td>\n",
       "      <td>261.200012</td>\n",
       "      <td>257632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>253.270004</td>\n",
       "      <td>260.809998</td>\n",
       "      <td>251.050003</td>\n",
       "      <td>253.419998</td>\n",
       "      <td>253.419998</td>\n",
       "      <td>224341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>255.699997</td>\n",
       "      <td>262.429993</td>\n",
       "      <td>253.529999</td>\n",
       "      <td>261.649994</td>\n",
       "      <td>261.649994</td>\n",
       "      <td>171369500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>260.559998</td>\n",
       "      <td>263.329987</td>\n",
       "      <td>256.220001</td>\n",
       "      <td>257.750000</td>\n",
       "      <td>257.750000</td>\n",
       "      <td>194881100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>247.979996</td>\n",
       "      <td>257.660004</td>\n",
       "      <td>243.899994</td>\n",
       "      <td>246.149994</td>\n",
       "      <td>246.149994</td>\n",
       "      <td>188601200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6843 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     1993-01-29   43.968750   43.968750   43.750000   43.937500   26.299288   \n",
       "1     1993-02-01   43.968750   44.250000   43.968750   44.250000   26.486324   \n",
       "2     1993-02-02   44.218750   44.375000   44.125000   44.343750   26.542448   \n",
       "3     1993-02-03   44.406250   44.843750   44.375000   44.812500   26.822998   \n",
       "4     1993-02-04   44.968750   45.093750   44.468750   45.000000   26.935240   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "6838  2020-03-26  249.520004  262.799988  249.050003  261.200012  261.200012   \n",
       "6839  2020-03-27  253.270004  260.809998  251.050003  253.419998  253.419998   \n",
       "6840  2020-03-30  255.699997  262.429993  253.529999  261.649994  261.649994   \n",
       "6841  2020-03-31  260.559998  263.329987  256.220001  257.750000  257.750000   \n",
       "6842  2020-04-01  247.979996  257.660004  243.899994  246.149994  246.149994   \n",
       "\n",
       "         Volume  \n",
       "0       1003200  \n",
       "1        480500  \n",
       "2        201300  \n",
       "3        529400  \n",
       "4        531500  \n",
       "...         ...  \n",
       "6838  257632800  \n",
       "6839  224341200  \n",
       "6840  171369500  \n",
       "6841  194881100  \n",
       "6842  188601200  \n",
       "\n",
       "[6843 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('etfs/SPY.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:30.825267Z",
     "iopub.status.busy": "2021-11-11T05:12:30.824593Z",
     "iopub.status.idle": "2021-11-11T05:12:30.854684Z",
     "shell.execute_reply": "2021-11-11T05:12:30.853894Z",
     "shell.execute_reply.started": "2021-11-11T05:12:30.825229Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting the index as date\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "df.index = df['Date']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:30.85663Z",
     "iopub.status.busy": "2021-11-11T05:12:30.856403Z",
     "iopub.status.idle": "2021-11-11T05:12:32.254507Z",
     "shell.execute_reply": "2021-11-11T05:12:32.253448Z",
     "shell.execute_reply.started": "2021-11-11T05:12:30.856604Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating dataframe with date and the target variable\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(data)):\n",
    "     new_data['Date'][i] = data['Date'][i]\n",
    "     new_data['Close'][i] = data['Close'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "\n",
    "### NOTE: While splitting the data into train and validation set, we cannot use random splitting since that will destroy the time component. So here we have set the last yearâ€™s data into validation and the 4 yearsâ€™ data before that into train set\n",
    "\n",
    "#### Additional: It would be interesting to see if we train it with more values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:32.256632Z",
     "iopub.status.busy": "2021-11-11T05:12:32.256259Z",
     "iopub.status.idle": "2021-11-11T05:12:32.265034Z",
     "shell.execute_reply": "2021-11-11T05:12:32.263793Z",
     "shell.execute_reply.started": "2021-11-11T05:12:32.256582Z"
    }
   },
   "outputs": [],
   "source": [
    "# splitting into train and validation\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "\n",
    "# shapes of training set\n",
    "print('\\n Shape of training set:')\n",
    "print(train.shape)\n",
    "\n",
    "# shapes of validation set\n",
    "print('\\n Shape of validation set:')\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions ðŸ”®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:32.266436Z",
     "iopub.status.busy": "2021-11-11T05:12:32.26619Z",
     "iopub.status.idle": "2021-11-11T05:12:38.198025Z",
     "shell.execute_reply": "2021-11-11T05:12:38.197161Z",
     "shell.execute_reply.started": "2021-11-11T05:12:32.266391Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(0,valid.shape[0]):\n",
    "    a = train['Close'][len(train)-5856+i:].sum() + sum(preds) # note: 5856 taken from shape of validation set\n",
    "    b = a/5856 \n",
    "    preds.append(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking the results (RMSE value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:38.199535Z",
     "iopub.status.busy": "2021-11-11T05:12:38.199298Z",
     "iopub.status.idle": "2021-11-11T05:12:38.213327Z",
     "shell.execute_reply": "2021-11-11T05:12:38.21249Z",
     "shell.execute_reply.started": "2021-11-11T05:12:38.199505Z"
    }
   },
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(valid['Close'])-preds),2)))\n",
    "print('\\n RMSE value on validation set:')\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:38.214918Z",
     "iopub.status.busy": "2021-11-11T05:12:38.214561Z",
     "iopub.status.idle": "2021-11-11T05:12:38.521722Z",
     "shell.execute_reply": "2021-11-11T05:12:38.52074Z",
     "shell.execute_reply.started": "2021-11-11T05:12:38.214886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here's our the actual stock price\n",
    "plt.plot(train['Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:38.523952Z",
     "iopub.status.busy": "2021-11-11T05:12:38.523308Z",
     "iopub.status.idle": "2021-11-11T05:12:38.833947Z",
     "shell.execute_reply": "2021-11-11T05:12:38.833055Z",
     "shell.execute_reply.started": "2021-11-11T05:12:38.5239Z"
    }
   },
   "outputs": [],
   "source": [
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = preds\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort the dataset in ascending order and create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:38.837009Z",
     "iopub.status.busy": "2021-11-11T05:12:38.836764Z",
     "iopub.status.idle": "2021-11-11T05:12:40.131043Z",
     "shell.execute_reply": "2021-11-11T05:12:40.130122Z",
     "shell.execute_reply.started": "2021-11-11T05:12:38.836982Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting index as date values\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "df.index = df['Date']\n",
    "\n",
    "#sorting\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "\n",
    "#creating a separate dataset so that any new feature created does not affect the original data\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    new_data['Date'][i] = data['Date'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features\n",
    "Hypothesis is that the first and last days of the week could potentially affect the closing price of the stock far more than the other days.  So we have created a feature that identifies whether a given day is Monday/Friday or Tuesday/Wednesday/Thursday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:40.133049Z",
     "iopub.status.busy": "2021-11-11T05:12:40.132582Z",
     "iopub.status.idle": "2021-11-11T05:12:41.968883Z",
     "shell.execute_reply": "2021-11-11T05:12:41.967624Z",
     "shell.execute_reply.started": "2021-11-11T05:12:40.133015Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data['mon_fri'] = 0\n",
    "\n",
    "for i in range(0,len(new_data)):\n",
    "    temp = pd.Timestamp(new_data['Date'][i])\n",
    "    if (temp.dayofweek == 0 or temp.dayofweek == 4):\n",
    "        new_data['mon_fri'][i] = 1\n",
    "    else:\n",
    "        new_data['mon_fri'][i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:41.970602Z",
     "iopub.status.busy": "2021-11-11T05:12:41.970337Z",
     "iopub.status.idle": "2021-11-11T05:12:42.027887Z",
     "shell.execute_reply": "2021-11-11T05:12:42.026791Z",
     "shell.execute_reply.started": "2021-11-11T05:12:41.970568Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "#split into train and validation\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "\n",
    "x_train = train.drop('Close', axis=1)\n",
    "y_train = train['Close']\n",
    "\n",
    "x_train['Date'] = pd.to_datetime(x_train['Date'])\n",
    "x_train['Date']=x_train['Date'].map(dt.datetime.toordinal)\n",
    "\n",
    "x_valid = valid.drop('Close', axis=1)\n",
    "\n",
    "x_valid['Date'] = pd.to_datetime(x_valid['Date'])\n",
    "x_valid['Date']=x_valid['Date'].map(dt.datetime.toordinal)\n",
    "\n",
    "y_valid = valid['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:42.031061Z",
     "iopub.status.busy": "2021-11-11T05:12:42.029335Z",
     "iopub.status.idle": "2021-11-11T05:12:42.191394Z",
     "shell.execute_reply": "2021-11-11T05:12:42.190008Z",
     "shell.execute_reply.started": "2021-11-11T05:12:42.031003Z"
    }
   },
   "outputs": [],
   "source": [
    "#implement linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:42.193511Z",
     "iopub.status.busy": "2021-11-11T05:12:42.193161Z",
     "iopub.status.idle": "2021-11-11T05:12:42.233196Z",
     "shell.execute_reply": "2021-11-11T05:12:42.232189Z",
     "shell.execute_reply.started": "2021-11-11T05:12:42.193465Z"
    }
   },
   "outputs": [],
   "source": [
    "#make predictions and find the rmse\n",
    "preds = model.predict(x_valid)\n",
    "rms=np.sqrt(np.mean(np.power((np.array(y_valid)-np.array(preds)),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:42.240682Z",
     "iopub.status.busy": "2021-11-11T05:12:42.239447Z",
     "iopub.status.idle": "2021-11-11T05:12:42.594573Z",
     "shell.execute_reply": "2021-11-11T05:12:42.593731Z",
     "shell.execute_reply.started": "2021-11-11T05:12:42.24061Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = preds\n",
    "\n",
    "valid.index = new_data[987:].index\n",
    "train.index = new_data[:987].index\n",
    "\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:42.596371Z",
     "iopub.status.busy": "2021-11-11T05:12:42.595929Z",
     "iopub.status.idle": "2021-11-11T05:12:42.66647Z",
     "shell.execute_reply": "2021-11-11T05:12:42.665224Z",
     "shell.execute_reply.started": "2021-11-11T05:12:42.596331Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:42.668645Z",
     "iopub.status.busy": "2021-11-11T05:12:42.668377Z",
     "iopub.status.idle": "2021-11-11T05:12:42.681546Z",
     "shell.execute_reply": "2021-11-11T05:12:42.68055Z",
     "shell.execute_reply.started": "2021-11-11T05:12:42.668615Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "x_valid_scaled = scaler.fit_transform(x_valid)\n",
    "x_valid = pd.DataFrame(x_valid_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using gridsearch to find the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:42.683352Z",
     "iopub.status.busy": "2021-11-11T05:12:42.682678Z",
     "iopub.status.idle": "2021-11-11T05:12:42.694538Z",
     "shell.execute_reply": "2021-11-11T05:12:42.693812Z",
     "shell.execute_reply.started": "2021-11-11T05:12:42.683315Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "model = GridSearchCV(knn, params, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:42.696214Z",
     "iopub.status.busy": "2021-11-11T05:12:42.695796Z",
     "iopub.status.idle": "2021-11-11T05:12:43.007739Z",
     "shell.execute_reply": "2021-11-11T05:12:43.006767Z",
     "shell.execute_reply.started": "2021-11-11T05:12:42.696168Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train)\n",
    "preds = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:43.009306Z",
     "iopub.status.busy": "2021-11-11T05:12:43.009042Z",
     "iopub.status.idle": "2021-11-11T05:12:43.023926Z",
     "shell.execute_reply": "2021-11-11T05:12:43.022894Z",
     "shell.execute_reply.started": "2021-11-11T05:12:43.009275Z"
    }
   },
   "outputs": [],
   "source": [
    "#rmse\n",
    "rms=np.sqrt(np.mean(np.power((np.array(y_valid)-np.array(preds)),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:12:43.025444Z",
     "iopub.status.busy": "2021-11-11T05:12:43.025137Z",
     "iopub.status.idle": "2021-11-11T05:12:43.346589Z",
     "shell.execute_reply": "2021-11-11T05:12:43.345651Z",
     "shell.execute_reply.started": "2021-11-11T05:12:43.025402Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = preds\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.plot(train['Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:14:38.434607Z",
     "iopub.status.busy": "2021-11-11T05:14:38.434282Z",
     "iopub.status.idle": "2021-11-11T05:14:38.458013Z",
     "shell.execute_reply": "2021-11-11T05:14:38.456723Z",
     "shell.execute_reply.started": "2021-11-11T05:14:38.434574Z"
    }
   },
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "\n",
    "train = data[:987]\n",
    "valid = data[987:]\n",
    "\n",
    "training = train['Close']\n",
    "validation = valid['Close']\n",
    "\n",
    "model = auto_arima(training, start_p=1, start_q=1,max_p=3, max_q=3, m=12,start_P=0, seasonal=True,d=1, D=1, trace=True,error_action='ignore',suppress_warnings=True)\n",
    "model.fit(training)\n",
    "\n",
    "forecast = model.predict(n_periods=248)\n",
    "forecast = pd.DataFrame(forecast,index = valid.index,columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:20:00.438593Z",
     "iopub.status.busy": "2021-11-11T05:20:00.436143Z",
     "iopub.status.idle": "2021-11-11T05:20:36.948181Z",
     "shell.execute_reply": "2021-11-11T05:20:36.947202Z",
     "shell.execute_reply.started": "2021-11-11T05:20:00.438497Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "#creating dataframe\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(data)):\n",
    "    new_data['Date'][i] = data['Date'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "train = dataset[0:987,:]\n",
    "valid = dataset[987:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:21:36.748031Z",
     "iopub.status.busy": "2021-11-11T05:21:36.747321Z",
     "iopub.status.idle": "2021-11-11T05:21:36.763762Z",
     "shell.execute_reply": "2021-11-11T05:21:36.762892Z",
     "shell.execute_reply.started": "2021-11-11T05:21:36.747986Z"
    }
   },
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T05:22:14.955196Z",
     "iopub.status.busy": "2021-11-11T05:22:14.953968Z",
     "iopub.status.idle": "2021-11-11T05:22:15.316014Z",
     "shell.execute_reply": "2021-11-11T05:22:15.314903Z",
     "shell.execute_reply.started": "2021-11-11T05:22:14.955139Z"
    }
   },
   "outputs": [],
   "source": [
    "#for plotting\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
